{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brent = pd.read_csv(\"./processed_tables/brent.csv\")\n",
    "df_precios = pd.read_csv(\"./processed_tables/precios.csv\")\n",
    "df_precipitacion = pd.read_csv(\"./processed_tables/precipitacion.csv\")\n",
    "df_temperatura = pd.read_csv(\"./processed_tables/temperatura.csv\")\n",
    "df_trm = pd.read_csv(\"./processed_tables/TRM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brent = df_brent.rename(columns={\"Fecha\": \"Date\"})\n",
    "df_precipitacion = df_precipitacion.rename(columns={\"date\": \"Date\"})\n",
    "df_temperatura = df_temperatura.rename(columns={\"date\": \"Date\"})\n",
    "df_trm = df_trm.rename(columns={\"vigenciadesde\": \"Date\"})\n",
    "\n",
    "# Perform left joins\n",
    "df_merged = pd.merge(df_precios, df_brent, on=\"Date\", how=\"left\")\n",
    "df_merged = pd.merge(df_merged, df_precipitacion, on=\"Date\", how=\"left\")\n",
    "df_merged = pd.merge(df_merged, df_temperatura, on=\"Date\", how=\"left\")\n",
    "df_merged = pd.merge(df_merged, df_trm, on=\"Date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'energy_price', 'brent_value', 'precipitacion_unidadmedida',\n",
       "       'precipitacion_amazonas', 'precipitacion_antioquia',\n",
       "       'precipitacion_arauca', 'precipitacion_atlantico',\n",
       "       'precipitacion_bogota', 'precipitacion_bolivar', 'precipitacion_boyaca',\n",
       "       'precipitacion_caldas', 'precipitacion_caqueta',\n",
       "       'precipitacion_casanare', 'precipitacion_cauca', 'precipitacion_cesar',\n",
       "       'precipitacion_choco', 'precipitacion_cordoba',\n",
       "       'precipitacion_cundinamarca', 'precipitacion_guainia',\n",
       "       'precipitacion_guaviare', 'precipitacion_huila',\n",
       "       'precipitacion_la guajira', 'precipitacion_magdalena',\n",
       "       'precipitacion_meta', 'precipitacion_narino',\n",
       "       'precipitacion_norte de santander', 'precipitacion_putumayo',\n",
       "       'precipitacion_quindio', 'precipitacion_risaralda',\n",
       "       'precipitacion_san andres providencia', 'precipitacion_santander',\n",
       "       'precipitacion_sucre', 'precipitacion_tolima',\n",
       "       'precipitacion_valle del cauca', 'precipitacion_vaupes',\n",
       "       'precipitacion_vichada', 'temp_AMAZONAS', 'temp_ANTIOQUIA',\n",
       "       'temp_ARAUCA',\n",
       "       'temp_ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA',\n",
       "       'temp_ATLANTICO', 'temp_BOGOTA', 'temp_BOLIVAR', 'temp_BOYACA',\n",
       "       'temp_CALDAS', 'temp_CAQUETA', 'temp_CASANARE', 'temp_CAUCA',\n",
       "       'temp_CESAR', 'temp_CHOCO', 'temp_CORDOBA', 'temp_CUNDINAMARCA',\n",
       "       'temp_GUAINIA', 'temp_GUAVIARE', 'temp_HUILA', 'temp_LA GUAJIRA',\n",
       "       'temp_MAGDALENA', 'temp_META', 'temp_NARINO', 'temp_NARIÑO',\n",
       "       'temp_NORTE DE SANTANDER', 'temp_PUTUMAYO', 'temp_QUINDIO',\n",
       "       'temp_RISARALDA', 'temp_SAN ANDRES PROVIDENCIA', 'temp_SANTANDER',\n",
       "       'temp_SUCRE', 'temp_TOLIMA', 'temp_VALLE DEL CAUCA', 'temp_VICHADA',\n",
       "       'TRM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 72)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha mínima: 2021-10-01\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fecha mínima: {df_merged.loc[0]['Date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha máxima: 2023-09-30\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fecha máxima: {df_merged.loc[df_merged.shape[0] - 1]['Date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_price</th>\n",
       "      <th>brent_value</th>\n",
       "      <th>precipitacion_amazonas</th>\n",
       "      <th>precipitacion_antioquia</th>\n",
       "      <th>precipitacion_arauca</th>\n",
       "      <th>precipitacion_atlantico</th>\n",
       "      <th>precipitacion_bogota</th>\n",
       "      <th>precipitacion_bolivar</th>\n",
       "      <th>precipitacion_boyaca</th>\n",
       "      <th>precipitacion_caldas</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_PUTUMAYO</th>\n",
       "      <th>temp_QUINDIO</th>\n",
       "      <th>temp_RISARALDA</th>\n",
       "      <th>temp_SAN ANDRES PROVIDENCIA</th>\n",
       "      <th>temp_SANTANDER</th>\n",
       "      <th>temp_SUCRE</th>\n",
       "      <th>temp_TOLIMA</th>\n",
       "      <th>temp_VALLE DEL CAUCA</th>\n",
       "      <th>temp_VICHADA</th>\n",
       "      <th>TRM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>644.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>644.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>322.121164</td>\n",
       "      <td>89.611661</td>\n",
       "      <td>6.270266</td>\n",
       "      <td>67.294067</td>\n",
       "      <td>9.849675</td>\n",
       "      <td>40.643075</td>\n",
       "      <td>10.772110</td>\n",
       "      <td>48.039756</td>\n",
       "      <td>106.116841</td>\n",
       "      <td>76.702240</td>\n",
       "      <td>...</td>\n",
       "      <td>22.912678</td>\n",
       "      <td>21.348549</td>\n",
       "      <td>21.506559</td>\n",
       "      <td>28.793119</td>\n",
       "      <td>19.625029</td>\n",
       "      <td>28.744456</td>\n",
       "      <td>21.675063</td>\n",
       "      <td>22.371571</td>\n",
       "      <td>27.284182</td>\n",
       "      <td>4313.503168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>241.618420</td>\n",
       "      <td>12.144518</td>\n",
       "      <td>11.016419</td>\n",
       "      <td>73.369778</td>\n",
       "      <td>16.005523</td>\n",
       "      <td>94.156330</td>\n",
       "      <td>19.197051</td>\n",
       "      <td>77.675716</td>\n",
       "      <td>117.254883</td>\n",
       "      <td>89.132885</td>\n",
       "      <td>...</td>\n",
       "      <td>3.764467</td>\n",
       "      <td>1.840646</td>\n",
       "      <td>1.700905</td>\n",
       "      <td>1.082577</td>\n",
       "      <td>2.349299</td>\n",
       "      <td>1.673011</td>\n",
       "      <td>1.451251</td>\n",
       "      <td>1.333940</td>\n",
       "      <td>1.325667</td>\n",
       "      <td>374.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>87.255265</td>\n",
       "      <td>70.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.975887</td>\n",
       "      <td>15.225000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>25.650000</td>\n",
       "      <td>13.125000</td>\n",
       "      <td>23.050000</td>\n",
       "      <td>13.950000</td>\n",
       "      <td>17.591995</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>3706.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>133.920626</td>\n",
       "      <td>80.808750</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>11.487600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.852500</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>4.915000</td>\n",
       "      <td>28.390000</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.081250</td>\n",
       "      <td>20.147299</td>\n",
       "      <td>20.483344</td>\n",
       "      <td>28.050000</td>\n",
       "      <td>18.078045</td>\n",
       "      <td>27.620833</td>\n",
       "      <td>20.917243</td>\n",
       "      <td>21.632185</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>3972.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>239.984244</td>\n",
       "      <td>85.955000</td>\n",
       "      <td>1.837000</td>\n",
       "      <td>41.588500</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>14.847000</td>\n",
       "      <td>3.535000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>64.226500</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>21.114753</td>\n",
       "      <td>21.503617</td>\n",
       "      <td>28.725000</td>\n",
       "      <td>18.973446</td>\n",
       "      <td>28.720833</td>\n",
       "      <td>21.736357</td>\n",
       "      <td>22.474095</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>4303.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>435.658130</td>\n",
       "      <td>95.925000</td>\n",
       "      <td>8.679500</td>\n",
       "      <td>101.030750</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.182500</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>140.482000</td>\n",
       "      <td>113.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>25.275000</td>\n",
       "      <td>22.651657</td>\n",
       "      <td>22.583292</td>\n",
       "      <td>29.550000</td>\n",
       "      <td>21.769216</td>\n",
       "      <td>29.750000</td>\n",
       "      <td>22.549100</td>\n",
       "      <td>23.327473</td>\n",
       "      <td>28.118750</td>\n",
       "      <td>4636.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1061.527174</td>\n",
       "      <td>123.440000</td>\n",
       "      <td>102.080000</td>\n",
       "      <td>432.219000</td>\n",
       "      <td>152.100000</td>\n",
       "      <td>1120.190000</td>\n",
       "      <td>188.700000</td>\n",
       "      <td>701.920000</td>\n",
       "      <td>733.292000</td>\n",
       "      <td>486.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>26.325000</td>\n",
       "      <td>31.450000</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>34.150000</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>25.147642</td>\n",
       "      <td>30.550000</td>\n",
       "      <td>5061.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy_price  brent_value  precipitacion_amazonas  \\\n",
       "count    644.000000   644.000000              616.000000   \n",
       "mean     322.121164    89.611661                6.270266   \n",
       "std      241.618420    12.144518               11.016419   \n",
       "min       87.255265    70.930000                0.000000   \n",
       "25%      133.920626    80.808750                0.090000   \n",
       "50%      239.984244    85.955000                1.837000   \n",
       "75%      435.658130    95.925000                8.679500   \n",
       "max     1061.527174   123.440000              102.080000   \n",
       "\n",
       "       precipitacion_antioquia  precipitacion_arauca  precipitacion_atlantico  \\\n",
       "count               616.000000            616.000000               616.000000   \n",
       "mean                 67.294067              9.849675                40.643075   \n",
       "std                  73.369778             16.005523                94.156330   \n",
       "min                   0.000000              0.000000                 0.000000   \n",
       "25%                  11.487600              0.000000                 4.852500   \n",
       "50%                  41.588500              2.300000                14.847000   \n",
       "75%                 101.030750             15.000000                35.182500   \n",
       "max                 432.219000            152.100000              1120.190000   \n",
       "\n",
       "       precipitacion_bogota  precipitacion_bolivar  precipitacion_boyaca  \\\n",
       "count            616.000000             616.000000            616.000000   \n",
       "mean              10.772110              48.039756            106.116841   \n",
       "std               19.197051              77.675716            117.254883   \n",
       "min                0.000000               0.000000              0.000000   \n",
       "25%                0.397500               4.915000             28.390000   \n",
       "50%                3.535000              16.200000             64.226500   \n",
       "75%               12.270000              66.000000            140.482000   \n",
       "max              188.700000             701.920000            733.292000   \n",
       "\n",
       "       precipitacion_caldas  ...  temp_PUTUMAYO  temp_QUINDIO  temp_RISARALDA  \\\n",
       "count            616.000000  ...     614.000000    614.000000      614.000000   \n",
       "mean              76.702240  ...      22.912678     21.348549       21.506559   \n",
       "std               89.132885  ...       3.764467      1.840646        1.700905   \n",
       "min                0.000000  ...       9.975887     15.225000       13.450000   \n",
       "25%                9.610000  ...      22.081250     20.147299       20.483344   \n",
       "50%               43.200000  ...      24.200000     21.114753       21.503617   \n",
       "75%              113.150000  ...      25.275000     22.651657       22.583292   \n",
       "max              486.500000  ...      27.750000     26.200000       26.325000   \n",
       "\n",
       "       temp_SAN ANDRES PROVIDENCIA  temp_SANTANDER  temp_SUCRE  temp_TOLIMA  \\\n",
       "count                   614.000000      614.000000  614.000000   614.000000   \n",
       "mean                     28.793119       19.625029   28.744456    21.675063   \n",
       "std                       1.082577        2.349299    1.673011     1.451251   \n",
       "min                      25.650000       13.125000   23.050000    13.950000   \n",
       "25%                      28.050000       18.078045   27.620833    20.917243   \n",
       "50%                      28.725000       18.973446   28.720833    21.736357   \n",
       "75%                      29.550000       21.769216   29.750000    22.549100   \n",
       "max                      31.450000       26.700000   34.150000    26.800000   \n",
       "\n",
       "       temp_VALLE DEL CAUCA  temp_VICHADA          TRM  \n",
       "count            614.000000    614.000000   644.000000  \n",
       "mean              22.371571     27.284182  4313.503168  \n",
       "std                1.333940      1.325667   374.097100  \n",
       "min               17.591995     20.600000  3706.950000  \n",
       "25%               21.632185     26.750000  3972.902500  \n",
       "50%               22.474095     27.300000  4303.340000  \n",
       "75%               23.327473     28.118750  4636.830000  \n",
       "max               25.147642     30.550000  5061.210000  \n",
       "\n",
       "[8 rows x 70 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitacion_columns = df_merged.filter(like='precipitacion_')\n",
    "temp_columns = df_merged.filter(like='temp_')\n",
    "specific_columns_df = df_merged[[\"brent_value\", \"TRM\"]]\n",
    "exogen_data = pd.concat([precipitacion_columns, temp_columns, specific_columns_df], axis=1)\n",
    "exogen_data.drop(\"precipitacion_unidadmedida\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de la data\n",
    "\n",
    "Para empezar a modelar la data, se debe estandarizar los datos, para ello se utilizará la librería `sklearn.preprocessing`, la cual nos permite estandarizar los datos de una manera sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.48678438,  0.91324172,  0.77225603, ..., -0.40328169,\n",
       "        -0.91731214, -1.33955165],\n",
       "       [-0.56963718,  0.81779798,  1.62265328, ...,  1.59734222,\n",
       "        -0.91731214, -1.42360583],\n",
       "       [-0.51603723,  0.41374779,  1.56012407, ...,  1.59734222,\n",
       "        -0.91731214, -1.42360583],\n",
       "       ...,\n",
       "       [-0.46970507, -0.77061673, -0.14692334, ...,  0.97450648,\n",
       "         0.54497666, -0.58828069],\n",
       "       [ 3.27411492, -0.61374906, -0.54085736, ...,  0.97450648,\n",
       "         0.491825  , -0.60976239],\n",
       "       [ 2.92889493, -0.65194293, -0.61589241, ...,  1.29536125,\n",
       "         0.491825  , -0.69485988]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(exogen_data)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/david/eafit/Proyecto-Integrador-Semestre1/python-notebooks/TablesJoined.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/david/eafit/Proyecto-Integrador-Semestre1/python-notebooks/TablesJoined.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)  \u001b[39m# n_components is the number of components to keep\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/david/eafit/Proyecto-Integrador-Semestre1/python-notebooks/TablesJoined.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m pca_result \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(scaled_data)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:460\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 460\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    461\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    464\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    478\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    479\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 483\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    484\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    485\u001b[0m )\n\u001b[1;32m    487\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         _assert_all_finite(\n\u001b[1;32m    958\u001b[0m             array,\n\u001b[1;32m    959\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    960\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    961\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    964\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    123\u001b[0m     X,\n\u001b[1;32m    124\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    125\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    126\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    127\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    128\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    129\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Proyecto-Integrador-Semestre1-ERzOjjfT/lib/python3.11/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)  # n_components is the number of components to keep\n",
    "pca_result = pca.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cov'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/david/eafit/Proyecto-Integrador-Semestre1/python-notebooks/TablesJoined.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/david/eafit/Proyecto-Integrador-Semestre1/python-notebooks/TablesJoined.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m scaled_data\u001b[39m.\u001b[39;49mcov()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cov'"
     ]
    }
   ],
   "source": [
    "scaled_data.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyecto-Integrador-Semestre1-ERzOjjfT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
